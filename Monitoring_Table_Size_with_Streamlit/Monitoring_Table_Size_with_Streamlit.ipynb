{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4fb15e-f9db-44eb-9f60-1b9589b755cb",
   "metadata": {
    "name": "md_title",
    "collapsed": false
   },
   "source": "# Monitoring the Table Size in Snowflake Notebooks with Streamlit\n\nA notebook that tracks the size of specific tables over time to help developers monitor storage growth trends. \n\nHere's what we're implementing to investigate the tables:\n1. Retrieve the Top 100 largest tables\n2. Analyze query patterns on the largest tables\n3. Identify which tables are users interacting with"
  },
  {
   "cell_type": "markdown",
   "id": "42a7b143-0779-4706-affc-c214213f55c5",
   "metadata": {
    "name": "md_section1",
    "collapsed": false
   },
   "source": "## 1. Retrieve the Top 100 largest tables\n\nThis query shows the top 100 largest tables, sorted by row count, including their size in GB, owners and last modification details."
  },
  {
   "cell_type": "code",
   "id": "e17f14a5-ea50-4a1d-bc15-c64a6447d0a8",
   "metadata": {
    "language": "sql",
    "name": "sql_top_tables",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Top 100 largest tables with metrics\nSELECT \n    CONCAT(TABLE_CATALOG, '.', TABLE_SCHEMA, '.', TABLE_NAME) AS FULLY_RESOLVED_TABLE_NAME,\n    TABLE_OWNER,\n    LAST_DDL,\n    LAST_DDL_BY,\n    ROW_COUNT,\n    ROUND(BYTES / 1024 / 1024 / 1024, 2) AS SIZE_GB,\n    LAST_ALTERED,\n    CASE \n        WHEN LAST_DDL <= DATEADD(DAY, -90, CURRENT_DATE) THEN 'YES' \n        ELSE 'NO' \n    END AS LAST_ACCESSED_90DAYS\nFROM SNOWFLAKE.ACCOUNT_USAGE.TABLES\nWHERE DELETED IS NULL\n  AND ROW_COUNT > 0\n  AND LAST_ACCESSED_90DAYS = 'NO'\nORDER BY ROW_COUNT DESC\nLIMIT 100;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "26cf2c60-f4a0-493d-bb62-fbde9e4226b9",
   "metadata": {
    "name": "md_variable_info",
    "collapsed": false
   },
   "source": "You can now run this query in Python without any additional code -- simply use your cell name as a variable! We're going to convert our cell to a pandas DataFrame below to make it easier to work with "
  },
  {
   "cell_type": "code",
   "id": "ac2608a7-5cd1-45fb-bb89-17f1bf010b5f",
   "metadata": {
    "language": "python",
    "name": "sql_top_tables_pd",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "sql_top_tables.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40d926ac-d441-4799-b56a-c200a13cbc09",
   "metadata": {
    "name": "md_section2",
    "collapsed": false
   },
   "source": "## 2. Explore a specific table \n\nLet's explore one of these tables in greater detail to figure out the most common queries and who is using it most often. \n\nðŸ’¡ **Pro tip:** You can interact with the below cell and select the fully resolved table name you want to explore more in your account!"
  },
  {
   "cell_type": "code",
   "id": "50216adb-e5e2-4dd0-8b82-0e7dae07d27f",
   "metadata": {
    "language": "python",
    "name": "py_input",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\nselection = st.text_input(label=\"Enter a fully resolved table path to explore\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "089287ef-efe4-423d-96ce-2ff4d53df21c",
   "metadata": {
    "name": "md_pass_variable",
    "collapsed": false
   },
   "source": "Let's now pass that variable into a SQL query so we can grab query analytics on this table"
  },
  {
   "cell_type": "code",
   "id": "7ad267bb-645d-4fa6-8e16-3666b2372fd8",
   "metadata": {
    "language": "sql",
    "name": "sql_most_expensive_queries_on_table",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Grab most expensive queries on this table \nSELECT \n    '{{selection}}' as FULLY_RESOLVED_TABLE_NAME,\n    q.QUERY_TEXT,\n    q.QUERY_TYPE,\n    SUM(CREDITS_USED_CLOUD_SERVICES) as CREDITS_USED,\n    MAX(TOTAL_ELAPSED_TIME) as MAX_elapsed_time,\n    AVG(TOTAL_ELAPSED_TIME)/1000 as AVG_EXECUTION_TIME_SEC\nFROM SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY q\nWHERE START_TIME >= CURRENT_DATE - interval '90 days'\n    AND query_text LIKE '%{{selection}}%'\nGROUP BY ALL\nORDER BY AVG_EXECUTION_TIME_SEC DESC\nLIMIT 10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14945658-f869-4047-b486-0a5456287948",
   "metadata": {
    "language": "python",
    "name": "py_visualization",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "df = sql_most_expensive_queries_on_table.to_pandas()\nst.dataframe(df,\n             column_config={\n                \"CREDITS_USED\": st.column_config.ProgressColumn(\n                \"CREDITS_USED\",\n                format=\"%.4f\",\n                min_value=df.CREDITS_USED.min(),\n                max_value=df.CREDITS_USED.max(),\n        ),\n    },)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d80fe813-7fe3-48a7-a30b-eb0b3495d0f3",
   "metadata": {
    "name": "md_section3",
    "collapsed": false
   },
   "source": "## 3. Find out which users most commonly query this table\n\nLet's say we want to take our top most expensive query and turn it into a materialization. Who will be the users who are most likely to be impacted by our activities? \n\nTo find out, we're going to grab the list of users who queried our table of interest in the last 90 days as well as the users who have executed the expensive query. We can then contact them when we make an update and tell them about improvements we made! ðŸŽ‰ \n\n-----\n\nFirst, let's find out who has used our table in the last 90 days.  We already have a variable `selection` we can use, so we're plugging it into the below query: "
  },
  {
   "cell_type": "code",
   "id": "23866f56-0731-492e-8306-4f6fc28ddb6e",
   "metadata": {
    "language": "sql",
    "name": "py_user_queries",
    "codeCollapsed": false,
    "collapsed": true
   },
   "outputs": [],
   "source": "-- Identify users who have queried selected table in last 90 days \nSELECT \n    USER_NAME, \n    COUNT(*) number_of_queries\nFROM SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY q\nWHERE START_TIME >= CURRENT_DATE - interval '90 days'\n    AND query_text LIKE '%{{selection}}%'\nGROUP BY ALL\nORDER BY number_of_queries DESC\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0aa5ad71-a360-4fbf-a9d3-868d1d7a329f",
   "metadata": {
    "name": "md_query_selection",
    "collapsed": false
   },
   "source": "Now, let's say we want to materialize a specific long running query. Grab a query from the `py_visualization` cell from Section 2. \n\nWe can now plug it into the `QUERY_TEXT` value below to find out who else would benefit from materializing this pattern. \n\nðŸ’¡ **Pro tip:** If the query is too long, try a unique subset of the query in the box below"
  },
  {
   "cell_type": "code",
   "id": "a041825e-a1fa-4d80-9e2b-9426ee818023",
   "metadata": {
    "language": "python",
    "name": "py_query_selection",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "query_selection = st.text_input(label=\"Enter the query text you want to look up\")\nst.write(\"**You Entered:** `\" + query_selection + \"`\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2368c7e-7325-4752-a2fb-ff4d6601123b",
   "metadata": {
    "name": "md_user_list",
    "collapsed": false
   },
   "source": "Sweet! Now we get a list of all the users who might have run this query, along with their total credit\nconsumption and query execution time over the last 90 days."
  },
  {
   "cell_type": "code",
   "id": "506d54d9-1a00-46df-9307-dcce94ce8fb9",
   "metadata": {
    "language": "sql",
    "name": "py_user_list",
    "collapsed": true,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT \n    USER_NAME, \n    SUM(CREDITS_USED_CLOUD_SERVICES) as total_credits, \n    MAX(TOTAL_ELAPSED_TIME) as MAX_elapsed_time,\n    AVG(TOTAL_ELAPSED_TIME)/1000 as AVG_EXECUTION_TIME_SEC\nFROM SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY q\nWHERE START_TIME >= CURRENT_DATE - interval '90 days'\n    AND query_text LIKE '%{{query_selection}}%'\nGROUP BY ALL\nORDER BY total_credits DESC",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f6e54924-57e2-4dfb-8bf1-bad9b7fb635d",
   "metadata": {
    "name": "md_resources",
    "collapsed": false
   },
   "source": "## What to learn more?\n\n- Snowflake Docs on [Account Usage](https://docs.snowflake.com/en/sql-reference/account-usage) and [QUERY_HISTORY view](https://docs.snowflake.com/en/sql-reference/account-usage/query_history)\n\n- More about [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake)\n\n- For more inspiration on how to use Streamlit widgets in Notebooks, check out [Streamlit Docs](https://docs.streamlit.io/) and this list of what is currently supported inside [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake#label-notebooks-streamlit-support)"
  }
 ]
}